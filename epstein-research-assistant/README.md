# ğŸ” Epstein Files Investigative Research Assistant

An AI-powered research tool for exploring the 25,000+ Epstein document pages using Google's Gemini File Search API. Ask natural language questions and get cited answers with links back to original sources.

## ğŸŒŸ Features

- **Natural Language Search**: Ask questions in plain English
- **Source Citations**: Every answer includes references to original Google Drive documents
- **Fully Managed RAG**: Powered by Gemini File Search (no vector database setup needed)
- **25K+ Documents**: Handles the complete Epstein files dataset
- **Fast & Accurate**: Uses Gemini 2.5 Flash for quick responses or Pro for deep analysis
- **Interactive UI**: Built with Streamlit for easy exploration

## ğŸ“‹ Prerequisites

- Python 3.11 or higher
- Google Gemini API key ([Get one here](https://ai.google.dev/))
- Epstein dataset CSV file (~100MB) from [HuggingFace](https://huggingface.co/datasets/tensonaut/EPSTEIN_FILES_20K)

## ğŸš€ Quick Start

### 1. Clone & Setup

```bash
cd epstein-research-assistant

# Create virtual environment
python -m venv .venv

# Activate virtual environment
# On macOS/Linux:
source .venv/bin/activate
# On Windows:
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
# Copy example .env file
cp .env.example .env

# Edit .env and add your Gemini API key
# GEMINI_API_KEY=your_api_key_here
```

### 3. Download Dataset

Download the Epstein dataset CSV from HuggingFace and place it in the `data/` folder:

```bash
# Create data directory if it doesn't exist
mkdir -p data

# Place your downloaded CSV here:
# data/epstein_dataset.csv
```

### 4. Run the Application

```bash
streamlit run src/app.py
```

The app will open in your browser at `http://localhost:8501`

## ğŸ“– How to Use

### Step 1: Load Dataset
1. The app will automatically detect your CSV file
2. Choose how many documents to process (start with 100 for testing)
3. Click "Process Documents"

### Step 2: Upload to Gemini
1. Click "Upload to Gemini" to create the search index
2. Wait for documents to upload (progress bar shows status)
3. First-time indexing costs ~$0.15 per 1M tokens

### Step 3: Ask Questions
1. Type your question in natural language
2. Click "Search"
3. View answer with source citations
4. Click on citations to see original document references

## ğŸ’¡ Example Questions

- "Who are the main individuals mentioned in the documents?"
- "What locations appear most frequently?"
- "Find all communications mentioning [specific person]"
- "What types of documents are included (emails, legal, travel)?"
- "Summarize documents about [specific topic/event]"
- "Are there any documents from [specific date range]?"

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI (src/app.py)         â”‚
â”‚   - Query input                     â”‚
â”‚   - Citation display                â”‚
â”‚   - Document upload                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Application Layer                 â”‚
â”‚   - CSV Processor                   â”‚
â”‚   - File Search Manager             â”‚
â”‚   - Query Engine                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Gemini File Search API            â”‚
â”‚   - Automatic chunking              â”‚
â”‚   - Vector embeddings               â”‚
â”‚   - Semantic search                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Gemini 2.5 Pro/Flash              â”‚
â”‚   - Answer generation               â”‚
â”‚   - Citation extraction             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
epstein-research-assistant/
â”œâ”€â”€ .env                          # API keys (create from .env.example)
â”œâ”€â”€ .env.example                  # Environment template
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ epstein_dataset.csv       # Your dataset (download separately)
â”‚   â””â”€â”€ processed/                # Temporary files (auto-generated)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                    # Streamlit application
â”‚   â”œâ”€â”€ config.py                 # Configuration management
â”‚   â”œâ”€â”€ csv_processor.py          # CSV parsing & processing
â”‚   â”œâ”€â”€ file_search_manager.py    # Gemini File Search operations
â”‚   â”œâ”€â”€ query_engine.py           # Query processing & formatting
â”‚   â””â”€â”€ utils.py                  # Helper functions
â””â”€â”€ notebooks/
    â””â”€â”€ data_exploration.ipynb    # Optional: Dataset analysis
```

## âš™ï¸ Configuration

Edit `.env` file to customize:

```bash
# Required
GEMINI_API_KEY=your_api_key_here

# Optional
MODEL_NAME=gemini-2.5-flash          # or gemini-2.5-pro
FILE_SEARCH_STORE_NAME=epstein_docs  # Custom store name
DATASET_PATH=data/epstein_dataset.csv
MAX_UPLOAD_BATCH=50                  # Upload batch size
```

## ğŸ’° Cost Estimation

Gemini File Search pricing (as of 2025):
- **Indexing**: $0.15 per 1M tokens (one-time)
- **Storage**: FREE
- **Queries**: FREE

**Estimated costs for 25K documents:**
- Assuming ~1K tokens/document average
- 25,000 documents Ã— 1,000 tokens = 25M tokens
- Cost: 25M Ã— $0.15/1M = **~$3.75 one-time**

Subsequent queries are FREE!

## ğŸ”§ Advanced Usage

### Using Different Models

**Gemini 2.5 Flash** (Default):
- Faster responses (1-2 seconds)
- Good for exploration & quick queries
- Lower latency

**Gemini 2.5 Pro**:
- Deeper analysis
- Better for complex multi-document synthesis
- More thorough citations

Change model in sidebar or `.env` file.

### Processing Full Dataset

Start with a small subset (100-1000 documents) for testing, then scale up:

```python
# In the UI, increase the document limit
# Or modify directly in code
processor.process_documents(limit=25000)  # Full dataset
```

### Custom System Instructions

Modify `query_engine.py` to customize how the AI responds:

```python
system_instruction = """
Your custom instructions here...
"""
```

## ğŸ› Troubleshooting

### CSV Not Found
- Ensure CSV is in `data/epstein_dataset.csv`
- Check `DATASET_PATH` in `.env`

### API Key Error
- Verify `GEMINI_API_KEY` in `.env`
- Get API key from https://ai.google.dev/

### Upload Timeout
- Reduce `MAX_UPLOAD_BATCH` in `.env`
- Try smaller document subset first

### Memory Issues
- Process documents in smaller batches
- Use pagination in CSV processing

## ğŸ“š Dataset Information

The Epstein Files dataset contains:
- ~25,000 document pages/emails
- OCR-processed text from JPG images
- Google Drive paths to original documents
- Released by House Oversight Committee

Download from: [HuggingFace - tensonaut/EPSTEIN_FILES_20K](https://huggingface.co/datasets/tensonaut/EPSTEIN_FILES_20K)

## ğŸ¤ Contributing

This is a research tool built for educational and investigative purposes. Feel free to:
- Submit issues for bugs
- Suggest improvements
- Fork and customize for your needs

## âš–ï¸ Legal & Ethics

- This tool is for research and investigative journalism
- All data comes from publicly released documents
- Citations link back to official sources
- Use responsibly and verify information

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ™ Acknowledgments

- Dataset by [@tensonaut](https://huggingface.co/tensonaut)
- Powered by Google Gemini API
- Built with Streamlit

## ğŸ“ Support

For issues or questions:
1. Check the troubleshooting section
2. Review [Gemini File Search docs](https://ai.google.dev/gemini-api/docs/file-search)
3. Open an issue on GitHub

---

**Built with â¤ï¸ for transparency and investigative research**
