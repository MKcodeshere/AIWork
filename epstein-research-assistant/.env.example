# Gemini API Configuration (for RAG backend)
GEMINI_API_KEY=your_gemini_api_key_here

# OpenAI API Configuration (for LLM frontend)
OPENAI_API_KEY=your_openai_api_key_here

# Model Configuration
# For LLM generation (OpenAI models)
LLM_MODEL=gpt-4o-mini
# Options: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo

# For RAG retrieval (Gemini)
RETRIEVAL_MODEL=gemini-2.5-flash
# Alternative: gemini-2.5-pro (not used for generation, only for File Search)

# File Search Store Configuration
FILE_SEARCH_STORE_NAME=epstein_documents_store

# Data Configuration
DATASET_PATH=data/epstein_dataset.csv

# Upload Configuration
MAX_UPLOAD_BATCH=5
CHUNK_SIZE=100

# Application Settings
APP_TITLE=Epstein Files Research Assistant
APP_ICON=üîç

# LLM Settings
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=2000
